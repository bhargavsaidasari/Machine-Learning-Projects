{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English-Hindi NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9si8kPTAbWNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VFCcEAzhuwD",
        "colab_type": "text"
      },
      "source": [
        "## Load the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy_Jh2d8hcEJ",
        "colab_type": "code",
        "outputId": "e0db2fcd-642c-4c8b-fd75-511f93677a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/Hindi_English_Dataset.csv', encoding='utf-8')\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ...                                     hindi_sentence\n",
              "0        ted  ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
              "1        ted  ...  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
              "2  indic2012  ...   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।\n",
              "3        ted  ...     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते\n",
              "4  indic2012  ...        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK2kGUndlWKw",
        "colab_type": "text"
      },
      "source": [
        "## Sources of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu4a5S5Ah2A5",
        "colab_type": "code",
        "outputId": "eaefa9fc-eeb5-43b3-874a-1265fc8d7286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset['source'].unique()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ted', 'indic2012', 'tides'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjWNTx5BlaKw",
        "colab_type": "text"
      },
      "source": [
        "## Length of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-um8lV8fQGv",
        "colab_type": "code",
        "outputId": "cba49f0f-01e1-41b8-800e-3db7d68b2b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(dataset.shape[0])\n",
        "# Randomly select 40000 sentences to train on \n",
        "\n",
        "dataset = dataset.sample(n=40000, random_state=42)\n",
        "dataset = dataset.sample(frac=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nJ0KHilyPq",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing steps\n",
        "### 1) Remove NaN rows\n",
        "### 2) Lower Case\n",
        "### 3) Remove punctuation\n",
        "### 4) Add start and end tags for target sequences\n",
        "### 5) One hot encoding for both the target and train sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynRaQpnmykef",
        "colab_type": "text"
      },
      "source": [
        "#### Remove NaN Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYROneAzyZvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D_jnIsAt6GN",
        "colab_type": "text"
      },
      "source": [
        "#### Lower case\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOFYgSQkt72c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['english_sentence'] = dataset['english_sentence'].apply(lambda x: x.lower())\n",
        "dataset['hindi_sentence'] = dataset['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmQhrx-suvPN",
        "colab_type": "text"
      },
      "source": [
        "#### Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NqMdCHqt0IY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "  stripped = [w.translate(table) for w in sentence.split()]\n",
        "  sentence = ' '.join(stripped) \n",
        "  return(sentence)\n",
        "\n",
        "\n",
        "dataset['english_sentence'] = dataset['english_sentence'].apply(lambda x: remove_punctuation(x))\n",
        "dataset['hindi_sentence'] = dataset['hindi_sentence'].apply(lambda x: remove_punctuation(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z6lDiosy7QU",
        "colab_type": "text"
      },
      "source": [
        "#### Add start and end tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGbU8zXay9-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['hindi_sentence'] = dataset['hindi_sentence'].apply(lambda x: '<start> ' + x + ' <end>')\n",
        "dataset['english_sentence'] = dataset['english_sentence'].apply(lambda x: x + ' <end>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK8hYEtrkT64",
        "colab_type": "text"
      },
      "source": [
        "#### Find maximum length of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmUkICPykWef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['length_english'] = dataset['english_sentence'].apply(lambda x: len(x.split()))\n",
        "dataset['length_hindi'] = dataset['hindi_sentence'].apply(lambda x: len(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdczqfMmMqF",
        "colab_type": "code",
        "outputId": "2e630022-e539-4e06-f733-a318f1733018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = dataset.loc[dataset['length_english'] < 20]\n",
        "dataset = dataset.loc[dataset['length_hindi'] < 20]\n",
        "print(dataset.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDdUGvhygFOP",
        "colab_type": "text"
      },
      "source": [
        "#### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZWqvix5jIkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary.\n",
        "\n",
        "    params: \n",
        "      text: The text of tv scripts split into words\n",
        "\n",
        "    returns: \n",
        "      A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    words_frequency = Counter(text)\n",
        "    sorted_frequency = sorted(words_frequency, key=words_frequency.get, reverse=True)\n",
        "    int_to_vocab = {ii+1: ch for ii, ch in enumerate(sorted_frequency)}\n",
        "    vocab_to_int = {ch: ii for ii, ch in int_to_vocab.items()}\n",
        "    # return tuple\n",
        "    return (vocab_to_int, int_to_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJaqJ5VsgJ_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_english_words = []\n",
        "all_hindi_words = []\n",
        "for i in range(dataset.shape[0]):\n",
        "  all_english_words.extend(dataset['english_sentence'].iloc[i].split())\n",
        "  all_hindi_words.extend(dataset['hindi_sentence'].iloc[i].split())\n",
        "\n",
        "english_vocab_to_int, english_int_to_vocab = create_lookup_tables(all_english_words)\n",
        "hindi_vocab_to_int, hindi_int_to_vocab = create_lookup_tables(all_hindi_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu0hWM6zt0D0",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vviHkbbat2kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_int_text = []\n",
        "hindi_int_text = []\n",
        "for i in range(dataset.shape[0]):\n",
        "  english_int_text.append([english_vocab_to_int[word] for word in dataset['english_sentence'].iloc[i].split()])\n",
        "  hindi_int_text.append([hindi_vocab_to_int[word] for word in dataset['hindi_sentence'].iloc[i].split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiqH8n8gnQnL",
        "colab_type": "text"
      },
      "source": [
        "#### Append zeros to make each row in the data equal length for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsNvBfHxnPpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_sequence(sentence_list):\n",
        "  return(max(len(x) for x in sentence_list))\n",
        "\n",
        "def padded_sequence(sentence_list):\n",
        "  max_length = max_sequence(sentence_list)\n",
        "  for i in range(len(sentence_list)):\n",
        "    sentence_list[i].extend([0] * (max_length - len(sentence_list[i])))\n",
        "  return(np.array(sentence_list)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oNvR9l51DA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_int_text = padded_sequence(english_int_text)\n",
        "hindi_int_text = padded_sequence(hindi_int_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNZP9ode2I1-",
        "colab_type": "text"
      },
      "source": [
        "#### Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlFzrW7q2IE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_length = int(0.8 * english_int_text.shape[0])\n",
        "# English train and test sets\n",
        "english_train_text = english_int_text[:train_length]\n",
        "english_test_text = english_int_text[train_length:]\n",
        "# Hindi train and test sets\n",
        "hindi_train_text = hindi_int_text[:train_length]\n",
        "hindi_test_text = hindi_int_text[train_length:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYgiEvGTvN00",
        "colab_type": "text"
      },
      "source": [
        "#### DataLoader Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YH6dUKcvQJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def batch_data(train_english, test_hindi, batch_size):\n",
        "  \"\"\"\n",
        "    Batch the neural network data using DataLoader.\n",
        "\n",
        "    Params: \n",
        "      words: The word ids of the TV scripts\n",
        "      sequence_length: The sequence length of each batch\n",
        "      batch_size: The size of each batch; the number of sequences in a batch\n",
        "\n",
        "    Returns: \n",
        "      DataLoader with batched data\n",
        "  \"\"\"\n",
        "  train_data = TensorDataset(torch.from_numpy(train_english), torch.from_numpy(test_hindi))\n",
        "  loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "  return(loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9QbAnFvjNwI",
        "colab_type": "code",
        "outputId": "723c7b4f-51ae-426b-d143-cb3d7d9bc728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataloader = batch_data(english_train_text, hindi_train_text, 64)\n",
        "# Test the dataloader\n",
        "for item in iter(dataloader):\n",
        "  train, test = item\n",
        "  print(\"Training Size is: \" + str(train.shape))\n",
        "  print(\"Testing Size is: \" + str(test.shape))\n",
        "  break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Size is: torch.Size([64, 19])\n",
            "Testing Size is: torch.Size([64, 19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxCAEyRZmAvS",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXzZ-uT0mDcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderGRU(nn.Module):\n",
        "  def __init__(self, vocab_size, embedded_size, encoding_size, max_len=19):\n",
        "    super(EncoderGRU, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_size = embedded_size\n",
        "    self.encoding_size = encoding_size\n",
        "    self.seq_len = max_len\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "    self.gru = nn.GRU(input_size=self.embedding_size, hidden_size=self.encoding_size,\n",
        "                      bidirectional=True, num_layers=2)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).permute(1, 0, 2)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self, batch_size):\n",
        "    return torch.zeros(2*2, batch_size, self.encoding_size, device=device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcVGUaw2Eya4",
        "colab_type": "text"
      },
      "source": [
        "#### Test Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z48D53yvk5mA",
        "colab_type": "code",
        "outputId": "73a7152e-ec81-42dc-a49c-9052dd61508d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = EncoderGRU(len(english_int_to_vocab), 256, 256, 20)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "english, hindi = next(iter(dataloader))\n",
        "\n",
        "hidden = encoder.initHidden(64)\n",
        "enc_output, enc_hidden = encoder(english.to(device), hidden)\n",
        "\n",
        "print(enc_output.size()) # max_length, batch_size, enc_units"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([19, 64, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10AZVjEaE1Hh",
        "colab_type": "text"
      },
      "source": [
        "#### Decoder module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf_XJjc7E3Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdannauAttention(nn.Module):\n",
        "  def __init__(self, hindi_vocab_size, embedding_size, attention_hidden_size, decoding_size,\\\n",
        "               encoding_size, seq_len=19):\n",
        "    super(BahdannauAttention, self).__init__()\n",
        "    self.embedding_size = embedding_size\n",
        "    self.vocab_size = hindi_vocab_size\n",
        "    self.decoding_size = decoding_size\n",
        "    self.encoding_size = encoding_size\n",
        "    self.hidden_size = attention_hidden_size\n",
        "    self.seq_len = seq_len\n",
        "    # inputs to output\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "    self.gru = nn.GRU(input_size=self.embedding_size + self.encoding_size, \n",
        "                      hidden_size=self.decoding_size, num_layers=2)\n",
        "    self.fc = nn.Linear(self.decoding_size, self.vocab_size)\n",
        "    # attention network\n",
        "    self.attention_input_encoder = nn.Linear(self.encoding_size, self.hidden_size)\n",
        "    self.attention_prev_state = nn.Linear(self.decoding_size, self.hidden_size)\n",
        "    self.v = nn.Linear(self.hidden_size, 1)\n",
        "\n",
        "\n",
        "  def forward(self, input, hidden, prev_encode):\n",
        "    prev_encode = prev_encode.permute(1, 0, 2)\n",
        "    hidden_permute = hidden.permute(1, 0, 2)\n",
        "    score = torch.tanh(self.attention_input_encoder(prev_encode) + \\\n",
        "                       torch.mean(self.attention_prev_state(hidden_permute), dim=1).unsqueeze(1))\n",
        "    attention_weights = F.softmax(self.v(score), dim=1)\n",
        "    context_vector = attention_weights * prev_encode\n",
        "    context_vector = torch.sum(context_vector, dim=1)\n",
        "    # compute embeddings of input\n",
        "    embeddings = self.embedding(input)\n",
        "    # concatanate embeddings and context vector\n",
        "    x = torch.cat((context_vector.unsqueeze(1), embeddings), -1).permute(1, 0, 2)\n",
        "    output, hidden = self.gru(x, hidden)\n",
        "    output = output.view(-1, self.decoding_size)\n",
        "    final_output = self.fc(output)\n",
        "    return final_output, hidden, attention_weights\n",
        "\n",
        "  def initHidden(self, batch_size):\n",
        "    return torch.zeros(2, batch_size, self.decoding_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9_SkvHUE4il",
        "colab_type": "text"
      },
      "source": [
        "#### Test Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ldV7n3E7LH",
        "colab_type": "code",
        "outputId": "55b2154e-56b5-4300-ca2e-c71507a76818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "decoder = BahdannauAttention(len(hindi_int_to_vocab), 256, 256, 512, 256 * 2, 19)\n",
        "\n",
        "decoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "english, hindi = next(iter(dataloader))\n",
        "\n",
        "hidden = decoder.initHidden(64)\n",
        "decoder_output, decoder_hidden, _ = decoder(hindi[:,0].unsqueeze(1).to(device), hidden, enc_output)\n",
        "\n",
        "print(decoder_output.size()) # max_length, batch_size, enc_units\n",
        "print(decoder_hidden.size())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 24167])\n",
            "torch.Size([2, 64, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Prx6LIjIIY",
        "colab_type": "text"
      },
      "source": [
        "#### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqeaAVzLX3cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "## TODO: Combine the encoder and decoder into one class\n",
        "encoder = EncoderGRU(len(english_int_to_vocab) + 1, 256, 256, 19)\n",
        "decoder = BahdannauAttention(len(hindi_int_to_vocab) + 1, 256, 256, 256*2, 256*2, 19)\n",
        "\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCsYhJ0YFM9",
        "colab_type": "code",
        "outputId": "c8bbed11-01d6-47cb-a90a-77e81ba0169e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(size_average=True, ignore_index=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "192ntOA0fSva",
        "colab_type": "code",
        "outputId": "17358a0a-a703-471f-f3a5-b72c4fa56d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "EPOCHS = 40\n",
        "teacher_forcing = 1\n",
        "import time\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    teacher_forcing = teacher_forcing * 0.99\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (english, hindi) in enumerate(dataloader):\n",
        "        loss = 0\n",
        "        if(english.size(0) != 64):\n",
        "          continue\n",
        "        else:\n",
        "          hidden = encoder.initHidden(english.size(0))\n",
        "\n",
        "          enc_output, enc_hidden = encoder(english.to(device), hidden.to(device))\n",
        "\n",
        "          dec_hidden = enc_hidden.view(2, english.size(0), -1)\n",
        "          dec_input = torch.tensor([[hindi_vocab_to_int['<start>']]] * english.size(0))\n",
        "          use_teacher_forcing = True if random.random() < teacher_forcing else False\n",
        "          if(use_teacher_forcing):\n",
        "            # use teacher forcing - feeding the target as the next input (via dec_input)\n",
        "            for t in range(1, hindi.size(1)):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                            dec_hidden.to(device), enc_output.to(device))\n",
        "                loss += criterion(predictions.to(device), hindi[:, t].to(device))\n",
        "                #loss += loss_\n",
        "                dec_input = hindi[:, t].unsqueeze(1)\n",
        "          else:\n",
        "            for t in range(1, hindi.size(1)):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                            dec_hidden.to(device), \n",
        "                                            enc_output.to(device))\n",
        "                loss += criterion(predictions.to(device), hindi[:, t].to(device))\n",
        "                topv, topi = predictions.topk(1)\n",
        "                dec_input = topi.detach()\n",
        "              \n",
        "          \n",
        "          batch_loss = loss\n",
        "          total_loss += batch_loss\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          loss.backward()\n",
        "\n",
        "          ### UPDATE MODEL PARAMETERS\n",
        "          optimizer.step()\n",
        "          \n",
        "          if batch % 100 == 0:\n",
        "              print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                          batch,\n",
        "                                                          batch_loss.detach().item()))\n",
        "          \n",
        "        \n",
        "    ### Save checkpoint for model\n",
        "    if epoch % 10 == 0 :\n",
        "      torch.save(encoder.state_dict(), '/content/encoder_3.pth')\n",
        "      torch.save(decoder.state_dict(), '/content/decoder_3.pth')\n",
        "\n",
        "    N_BATCH = english_train_text.shape[0] // 64\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 181.5998\n",
            "Epoch 1 Batch 100 Loss 114.0977\n",
            "Epoch 1 Batch 200 Loss 104.1697\n",
            "Epoch 1 Batch 300 Loss 99.1777\n",
            "Epoch 1 Loss 110.6428\n",
            "Time taken for 1 epoch 24.933582067489624 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 99.7507\n",
            "Epoch 2 Batch 100 Loss 102.4824\n",
            "Epoch 2 Batch 200 Loss 97.2365\n",
            "Epoch 2 Batch 300 Loss 93.1837\n",
            "Epoch 2 Loss 97.5611\n",
            "Time taken for 1 epoch 24.828964948654175 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 93.2880\n",
            "Epoch 3 Batch 100 Loss 89.3266\n",
            "Epoch 3 Batch 200 Loss 80.7259\n",
            "Epoch 3 Batch 300 Loss 92.3335\n",
            "Epoch 3 Loss 89.5865\n",
            "Time taken for 1 epoch 24.787257194519043 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 82.5304\n",
            "Epoch 4 Batch 100 Loss 73.9707\n",
            "Epoch 4 Batch 200 Loss 80.8019\n",
            "Epoch 4 Batch 300 Loss 80.9817\n",
            "Epoch 4 Loss 82.2927\n",
            "Time taken for 1 epoch 24.858264207839966 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 74.0057\n",
            "Epoch 5 Batch 100 Loss 71.0280\n",
            "Epoch 5 Batch 200 Loss 72.5651\n",
            "Epoch 5 Batch 300 Loss 75.2797\n",
            "Epoch 5 Loss 75.3787\n",
            "Time taken for 1 epoch 24.86519193649292 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 61.6106\n",
            "Epoch 6 Batch 100 Loss 63.5122\n",
            "Epoch 6 Batch 200 Loss 63.9540\n",
            "Epoch 6 Batch 300 Loss 68.7776\n",
            "Epoch 6 Loss 68.7278\n",
            "Time taken for 1 epoch 24.78433918952942 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 54.0768\n",
            "Epoch 7 Batch 100 Loss 60.8332\n",
            "Epoch 7 Batch 200 Loss 58.7197\n",
            "Epoch 7 Batch 300 Loss 62.0565\n",
            "Epoch 7 Loss 60.9872\n",
            "Time taken for 1 epoch 24.766651391983032 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 92.7590\n",
            "Epoch 8 Batch 100 Loss 51.3471\n",
            "Epoch 8 Batch 200 Loss 51.1253\n",
            "Epoch 8 Batch 300 Loss 51.0437\n",
            "Epoch 8 Loss 57.3696\n",
            "Time taken for 1 epoch 24.822676420211792 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 42.4768\n",
            "Epoch 9 Batch 100 Loss 41.0677\n",
            "Epoch 9 Batch 200 Loss 47.0221\n",
            "Epoch 9 Batch 300 Loss 47.2740\n",
            "Epoch 9 Loss 49.3444\n",
            "Time taken for 1 epoch 24.861103534698486 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 39.4156\n",
            "Epoch 10 Batch 100 Loss 38.4242\n",
            "Epoch 10 Batch 200 Loss 39.1853\n",
            "Epoch 10 Batch 300 Loss 41.2104\n",
            "Epoch 10 Loss 46.6254\n",
            "Time taken for 1 epoch 24.832807302474976 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 31.7032\n",
            "Epoch 11 Batch 100 Loss 34.1520\n",
            "Epoch 11 Batch 200 Loss 33.8285\n",
            "Epoch 11 Batch 300 Loss 36.5825\n",
            "Epoch 11 Loss 41.9457\n",
            "Time taken for 1 epoch 24.95576286315918 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 29.4408\n",
            "Epoch 12 Batch 100 Loss 31.2031\n",
            "Epoch 12 Batch 200 Loss 31.1933\n",
            "Epoch 12 Batch 300 Loss 35.3864\n",
            "Epoch 12 Loss 37.5967\n",
            "Time taken for 1 epoch 24.8586106300354 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 25.4336\n",
            "Epoch 13 Batch 100 Loss 26.0985\n",
            "Epoch 13 Batch 200 Loss 30.4224\n",
            "Epoch 13 Batch 300 Loss 29.6865\n",
            "Epoch 13 Loss 35.5040\n",
            "Time taken for 1 epoch 24.992062091827393 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 23.8806\n",
            "Epoch 14 Batch 100 Loss 26.3149\n",
            "Epoch 14 Batch 200 Loss 25.8582\n",
            "Epoch 14 Batch 300 Loss 27.4564\n",
            "Epoch 14 Loss 32.8298\n",
            "Time taken for 1 epoch 25.13079857826233 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 20.9984\n",
            "Epoch 15 Batch 100 Loss 22.2615\n",
            "Epoch 15 Batch 200 Loss 23.0479\n",
            "Epoch 15 Batch 300 Loss 21.9915\n",
            "Epoch 15 Loss 28.4420\n",
            "Time taken for 1 epoch 25.121597290039062 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 18.3446\n",
            "Epoch 16 Batch 100 Loss 21.1288\n",
            "Epoch 16 Batch 200 Loss 20.7424\n",
            "Epoch 16 Batch 300 Loss 78.4578\n",
            "Epoch 16 Loss 28.4634\n",
            "Time taken for 1 epoch 24.835583448410034 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 18.1176\n",
            "Epoch 17 Batch 100 Loss 75.0491\n",
            "Epoch 17 Batch 200 Loss 18.7299\n",
            "Epoch 17 Batch 300 Loss 19.1798\n",
            "Epoch 17 Loss 27.9525\n",
            "Time taken for 1 epoch 24.871610403060913 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 72.6781\n",
            "Epoch 18 Batch 100 Loss 15.4488\n",
            "Epoch 18 Batch 200 Loss 76.1195\n",
            "Epoch 18 Batch 300 Loss 16.7601\n",
            "Epoch 18 Loss 25.7227\n",
            "Time taken for 1 epoch 24.937500953674316 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 12.3837\n",
            "Epoch 19 Batch 100 Loss 64.9527\n",
            "Epoch 19 Batch 200 Loss 67.3703\n",
            "Epoch 19 Batch 300 Loss 16.6323\n",
            "Epoch 19 Loss 22.7645\n",
            "Time taken for 1 epoch 24.8351092338562 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 10.5166\n",
            "Epoch 20 Batch 100 Loss 12.9972\n",
            "Epoch 20 Batch 200 Loss 68.3483\n",
            "Epoch 20 Batch 300 Loss 16.0754\n",
            "Epoch 20 Loss 21.6579\n",
            "Time taken for 1 epoch 24.842572927474976 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 11.7497\n",
            "Epoch 21 Batch 100 Loss 59.7696\n",
            "Epoch 21 Batch 200 Loss 13.7040\n",
            "Epoch 21 Batch 300 Loss 11.6748\n",
            "Epoch 21 Loss 22.2914\n",
            "Time taken for 1 epoch 25.056522846221924 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 11.2930\n",
            "Epoch 22 Batch 100 Loss 11.2459\n",
            "Epoch 22 Batch 200 Loss 10.6465\n",
            "Epoch 22 Batch 300 Loss 12.9672\n",
            "Epoch 22 Loss 22.0309\n",
            "Time taken for 1 epoch 24.921462297439575 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 8.9488\n",
            "Epoch 23 Batch 100 Loss 8.7748\n",
            "Epoch 23 Batch 200 Loss 57.5708\n",
            "Epoch 23 Batch 300 Loss 47.9242\n",
            "Epoch 23 Loss 20.2515\n",
            "Time taken for 1 epoch 24.921448469161987 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 8.8553\n",
            "Epoch 24 Batch 100 Loss 9.0580\n",
            "Epoch 24 Batch 200 Loss 9.3715\n",
            "Epoch 24 Batch 300 Loss 9.0812\n",
            "Epoch 24 Loss 19.5526\n",
            "Time taken for 1 epoch 24.85662055015564 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 45.6191\n",
            "Epoch 25 Batch 100 Loss 8.4647\n",
            "Epoch 25 Batch 200 Loss 9.3197\n",
            "Epoch 25 Batch 300 Loss 9.2998\n",
            "Epoch 25 Loss 18.5263\n",
            "Time taken for 1 epoch 24.848914623260498 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 8.0128\n",
            "Epoch 26 Batch 100 Loss 50.2694\n",
            "Epoch 26 Batch 200 Loss 7.1470\n",
            "Epoch 26 Batch 300 Loss 6.4684\n",
            "Epoch 26 Loss 15.0048\n",
            "Time taken for 1 epoch 24.84000873565674 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 5.7397\n",
            "Epoch 27 Batch 100 Loss 5.7198\n",
            "Epoch 27 Batch 200 Loss 42.1143\n",
            "Epoch 27 Batch 300 Loss 6.1722\n",
            "Epoch 27 Loss 13.9557\n",
            "Time taken for 1 epoch 24.875185251235962 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 7.0693\n",
            "Epoch 28 Batch 100 Loss 4.8227\n",
            "Epoch 28 Batch 200 Loss 36.6224\n",
            "Epoch 28 Batch 300 Loss 7.4261\n",
            "Epoch 28 Loss 13.3450\n",
            "Time taken for 1 epoch 24.9290452003479 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 37.1206\n",
            "Epoch 29 Batch 100 Loss 6.7380\n",
            "Epoch 29 Batch 200 Loss 5.4937\n",
            "Epoch 29 Batch 300 Loss 7.5556\n",
            "Epoch 29 Loss 13.7494\n",
            "Time taken for 1 epoch 24.841551542282104 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 5.1894\n",
            "Epoch 30 Batch 100 Loss 4.7182\n",
            "Epoch 30 Batch 200 Loss 8.2073\n",
            "Epoch 30 Batch 300 Loss 6.7914\n",
            "Epoch 30 Loss 11.7143\n",
            "Time taken for 1 epoch 24.911068439483643 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 30.4237\n",
            "Epoch 31 Batch 100 Loss 32.7750\n",
            "Epoch 31 Batch 200 Loss 4.8223\n",
            "Epoch 31 Batch 300 Loss 5.4255\n",
            "Epoch 31 Loss 11.6231\n",
            "Time taken for 1 epoch 24.99324321746826 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 3.5634\n",
            "Epoch 32 Batch 100 Loss 4.6412\n",
            "Epoch 32 Batch 200 Loss 4.4219\n",
            "Epoch 32 Batch 300 Loss 5.2926\n",
            "Epoch 32 Loss 12.2578\n",
            "Time taken for 1 epoch 24.895045280456543 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 43.6045\n",
            "Epoch 33 Batch 100 Loss 3.7236\n",
            "Epoch 33 Batch 200 Loss 26.5152\n",
            "Epoch 33 Batch 300 Loss 5.0537\n",
            "Epoch 33 Loss 9.4265\n",
            "Time taken for 1 epoch 24.89254593849182 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 22.7132\n",
            "Epoch 34 Batch 100 Loss 14.3729\n",
            "Epoch 34 Batch 200 Loss 4.8877\n",
            "Epoch 34 Batch 300 Loss 20.0056\n",
            "Epoch 34 Loss 8.7404\n",
            "Time taken for 1 epoch 24.89241933822632 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 2.7734\n",
            "Epoch 35 Batch 100 Loss 2.7211\n",
            "Epoch 35 Batch 200 Loss 24.4753\n",
            "Epoch 35 Batch 300 Loss 3.4854\n",
            "Epoch 35 Loss 6.6690\n",
            "Time taken for 1 epoch 24.845090866088867 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 19.5568\n",
            "Epoch 36 Batch 100 Loss 7.8297\n",
            "Epoch 36 Batch 200 Loss 3.2207\n",
            "Epoch 36 Batch 300 Loss 16.6053\n",
            "Epoch 36 Loss 6.6249\n",
            "Time taken for 1 epoch 24.868117809295654 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.2503\n",
            "Epoch 37 Batch 100 Loss 2.1423\n",
            "Epoch 37 Batch 200 Loss 2.1020\n",
            "Epoch 37 Batch 300 Loss 15.1976\n",
            "Epoch 37 Loss 6.4093\n",
            "Time taken for 1 epoch 24.94502353668213 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.6699\n",
            "Epoch 38 Batch 100 Loss 3.3817\n",
            "Epoch 38 Batch 200 Loss 3.0246\n",
            "Epoch 38 Batch 300 Loss 11.4725\n",
            "Epoch 38 Loss 5.8443\n",
            "Time taken for 1 epoch 24.845563888549805 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 1.6657\n",
            "Epoch 39 Batch 100 Loss 2.2333\n",
            "Epoch 39 Batch 200 Loss 11.9317\n",
            "Epoch 39 Batch 300 Loss 2.4628\n",
            "Epoch 39 Loss 5.3630\n",
            "Time taken for 1 epoch 24.85361957550049 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 1.9336\n",
            "Epoch 40 Batch 100 Loss 2.0236\n",
            "Epoch 40 Batch 200 Loss 2.1416\n",
            "Epoch 40 Batch 300 Loss 2.5209\n",
            "Epoch 40 Loss 5.7554\n",
            "Time taken for 1 epoch 24.888495445251465 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtdnARFOHgo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(encoder.state_dict(), '/content/encoder_3.pth')\n",
        "torch.save(decoder.state_dict(), '/content/decoder_3.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJU29FRhwoen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_inference(text, encoder, decoder):\n",
        "  \"\"\" Computes the greedy search output for the network.\n",
        "\n",
        "    Parameters:\n",
        "      text(string): input to run inference on\n",
        "      encoder(nn.Module): trained encoder module\n",
        "      decoder(nn.Module): trained decoder module\n",
        "\n",
        "    Returns:\n",
        "      decoded_words(string): inference output\n",
        "      decoder_attentions(torch.tensor): attention scores for each word\n",
        "  \"\"\"  \n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "  hidden = encoder.initHidden(1)\n",
        "  input_text = [english_vocab_to_int[x.lower()] for x in text.split()]\n",
        "  input_text.extend([0] * (19 - len(input_text)))\n",
        "  input_text = torch.from_numpy(np.array(input_text)).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    enc_output, enc_hidden = encoder(input_text.to(device), hidden.to(device))\n",
        "    dec_hidden = enc_hidden.view(2, 1, -1)\n",
        "    dec_input = torch.tensor([[hindi_vocab_to_int['<start>']]])\n",
        "    decoder_attentions = torch.zeros(19, 19)\n",
        "    decoded_words = []\n",
        "    for di in range(19):\n",
        "        predictions, dec_hidden, dec_attentions = decoder(dec_input.to(device), dec_hidden.to(device), \n",
        "                                            enc_output.to(device))\n",
        "        decoder_attentions[di] = dec_attentions.data.squeeze()\n",
        "        topv, topi = predictions.data.topk(1)\n",
        "        if topi.item() == hindi_vocab_to_int['<end>']:\n",
        "          decoded_words.append('<end>')\n",
        "          break\n",
        "        else:\n",
        "          decoded_words.append(hindi_int_to_vocab[topi.item()])\n",
        "          dec_input = topi\n",
        "  return(' '.join(decoded_words), decoder_attentions)\n",
        "         \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHj2uYlyL76-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = [(english_int_to_vocab[x]) for x in list(english_test_text[0]) if x != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvfPbtjqfh1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output, attentions = greedy_inference('Does this work as intended <end>', encoder, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MUqcu3AifMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64393842-aeef-4cd1-dfb2-4fcc2b1774be"
      },
      "source": [
        "output"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'क्या यह काम के रूप में हैं <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMgOe7bIfJr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "5656fdc0-bcd8-49e2-f053-55780178d9e9"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('classic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(attentions[:6, :6].numpy(), cmap='gray')\n",
        "fig.colorbar(cax)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f33441f4f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}